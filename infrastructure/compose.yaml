version: '2'
services:

  # Kafka infrastructure services (zookeeper + kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
      - 29092:29092
    networks:
      - kafka-network
    environment:
      KAFKA_BROKER_ID: 0
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka:9092,LISTENER_EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

  # Python Producer Service
  my-python-producer:
    image: mpradeep954/fetch-de-data-gen
    depends_on:
      - kafka
    restart: on-failure:10
    ports:
      - 9093:9093
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: user-login
    networks:
      - kafka-network
  
  # Apache spark master with workers A and B
  spark-master:
    image: apache-spark:3.5.3
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - kafka-network
    volumes:
       - ../app:/opt/spark-apps
       - ../data_lake:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master

  spark-worker-a:
    image: apache-spark:3.5.3
    ports:
      - "9091:8080"
      - "7001:7000"
    depends_on:
      - spark-master
    networks:
      - kafka-network
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    volumes:
       - ../app:/opt/spark-apps
       - ../data_lake:/opt/spark-data

  spark-worker-b:
    image: apache-spark:3.5.3
    ports:
      - "9095:8080"
      - "7002:7000"
    depends_on:
      - spark-master
    networks:
      - kafka-network
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    volumes:
       - ../app:/opt/spark-apps
       - ../data_lake:/opt/spark-data

  # Visualization server (streamlit)
  visualization-server:
    image: streamlit-server:1.0.0
    ports:
      - "10501:8501"
    depends_on:
      - spark-master
      - my-python-producer
    networks:
      - kafka-network

# Connect all services together
networks:
  kafka-network:
    driver: bridge